{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - Random Forests\n",
    "## Hudson Arney & Ian Golvach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Social_Network_Ads.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df, x='Age', y='EstimatedSalary', hue='Purchased')\n",
    "plt.title('Age vs Estimated Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch implemntation of RF\n",
    "Learning sourced from: https://en.wikipedia.org/wiki/Random_forest\n",
    "\n",
    "Based on the wikipedia article, we will need to modify a standard decision tree model so that\n",
    " - Along with the gini coef. split, we select a random subset of the feature to consider when making splits\n",
    " - Several decision trees are trained with a 'bagging' approach, training the trees on a random swample w/ replacement of the data.\n",
    " \n",
    "Following this, it makes the most sense that we first implement a method that will handle the sampling and training, as well as the predicting via plurality, and another method that will server as the model itself for the underlying decision trees (that way we can test the bagging concept with other models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "class bagging_tree:\n",
    "    \"\"\"Bootstrap aggregates a decision tree, bagging B times\"\"\"\n",
    "    def __init__(self, model, B=5, is_classifier=True):\n",
    "        self.B = B\n",
    "        self.model = model\n",
    "        self.fitted_models = []\n",
    "        self.is_classifier = is_classifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Create B models fitted on n sets created by randomly sampling with replacement from X and y\n",
    "        if(X.shape[0] != y.shape[0]):\n",
    "            raise Exception(\"X and y do not have the same number of columns\")\n",
    "        for i in range(self.B):\n",
    "            bag_X = []\n",
    "            bag_y = []\n",
    "            for i in range(X.shape[0]):\n",
    "                sample_ind = np.random.randint(X.shape[0])\n",
    "                bag_X.append(X[sample_ind])\n",
    "                bag_y.append(y[sample_ind])\n",
    "            new_model = self.model()\n",
    "            new_model.fit(np.array(bag_X), np.array(bag_y))\n",
    "            self.fitted_models.append(new_model)\n",
    "            \n",
    "    def predict(self, X_pred):\n",
    "        # Return the average of predictions if regression, otherwise return plurality of predictions\n",
    "        # It may be advantageous to later replace these with np functions\n",
    "        predictions = []\n",
    "        for i in range(self.B):\n",
    "            predictions.append(self.fitted_models[i].predict(X_pred))\n",
    "        if(self.is_classifier):\n",
    "            return np.ravel(scipy.stats.mode(np.array(predictions).T,1)[0])\n",
    "        else:\n",
    "            return np.mean(np.array(predictions).T,1)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is just a proof of concept that the class actually works, which is why train/test splitting was not performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_tree = bagging_tree(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df[['Age','EstimatedSalary']])\n",
    "y= np.array(df['Purchased'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_tree.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
